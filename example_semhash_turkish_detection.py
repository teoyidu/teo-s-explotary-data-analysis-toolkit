#!/usr/bin/env python3
"""
Simple example demonstrating SemHash Turkish duplicate detection
"""

import pandas as pd
import sys
import os

# Add the project root to the path
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

def main():
    """Demonstrate SemHash Turkish duplicate detection"""
    
    print("üîç SemHash Turkish Duplicate Detection Example")
    print("="*50)
    
    # Sample Turkish text data with various types of duplicates
    sample_data = {
        'text': [
            # Exact duplicates
            "Merhaba, nasƒ±lsƒ±nƒ±z? Bug√ºn hava √ßok g√ºzel.",
            "Merhaba, nasƒ±lsƒ±nƒ±z? Bug√ºn hava √ßok g√ºzel.",
            "Merhaba, nasƒ±lsƒ±nƒ±z? Bug√ºn hava √ßok g√ºzel.",
            
            # Near duplicates with punctuation differences
            "Merhaba! Nasƒ±lsƒ±nƒ±z? Bug√ºn hava √ßok g√ºzel.",
            "Merhaba, nasƒ±lsƒ±nƒ±z? Bug√ºn hava √ßok g√ºzel!",
            
            # Similar meaning, different wording
            "Bug√ºn hava √ßok g√ºzel ve g√ºne≈üli.",
            "Hava bug√ºn √ßok g√ºzel, g√ºne≈üli bir g√ºn.",
            
            # Legal text duplicates
            "Bu s√∂zle≈üme taraflar arasƒ±nda imzalanmƒ±≈ütƒ±r.",
            "Bu s√∂zle≈üme taraflar arasƒ±nda imzalanmƒ±≈ütƒ±r.",
            "Bu s√∂zle≈üme, taraflar arasƒ±nda imzalanmƒ±≈ütƒ±r.",
            
            # News text duplicates
            "Ekonomi bakanƒ± yeni √∂nlemler a√ßƒ±kladƒ±.",
            "Ekonomi bakanƒ± yeni √∂nlemler a√ßƒ±kladƒ±.",
            "Ekonomi Bakanƒ± yeni √∂nlemler a√ßƒ±kladƒ±.",
            
            # Unique texts
            "ƒ∞stanbul'da ya≈üƒ±yorum ve √ßok mutluyum.",
            "Ankara'da √ßalƒ±≈üƒ±yorum ve memnunum.",
            "ƒ∞zmir'de tatil yapƒ±yorum.",
        ]
    }
    
    df = pd.DataFrame(sample_data)
    
    print(f"Original DataFrame: {len(df)} texts")
    print("\nSample texts:")
    for i, text in enumerate(df['text'][:5]):
        print(f"  {i}: {text}")
    
    print("\n" + "="*50)
    
    # Try to import and use SemHash Turkish detector
    try:
        from src.data_quality.processors.semhash_turkish_detector import SemHashTurkishDetector
        print("‚úÖ SemHash Turkish detector imported successfully")
        
        # Configuration for Turkish duplicate detection
        config = {
            'text_column': 'text',
            'similarity_threshold': 0.8,
            'action': 'semhash',
            'remove_stopwords': True,
            'normalize_text': True,
            'min_word_length': 2,
            'use_multilingual_model': True,
            'use_ann': True
        }
        
        print("\nüîß Initializing SemHash Turkish detector...")
        detector = SemHashTurkishDetector(config)
        
        print("üîÑ Processing texts for duplicate detection...")
        result_df, stats = detector.process_with_statistics(df)
        
        print("\nüìä Results:")
        print(f"  Original texts: {stats['original_count']}")
        print(f"  Duplicates found: {stats['duplicate_count']}")
        print(f"  Unique texts: {stats['unique_count']}")
        print(f"  Duplicate percentage: {stats['duplicate_percentage']:.1f}%")
        print(f"  Method used: {stats['method_used']}")
        print(f"  Model used: {stats['model_used']}")
        
        print("\nüìã Duplicate groups:")
        if 'duplicate_group' in result_df.columns:
            duplicate_groups = result_df[result_df['duplicate_group'] >= 0].groupby('duplicate_group')
            
            if len(duplicate_groups) > 0:
                for group_id, group in duplicate_groups:
                    print(f"\n  Group {group_id} ({len(group)} texts):")
                    for idx, row in group.iterrows():
                        print(f"    Row {idx}: {row['text']}")
            else:
                print("  No duplicate groups found")
        else:
            print("  No duplicate group information available")
            
        print("\n‚úÖ SemHash Turkish duplicate detection completed successfully!")
        
    except ImportError as e:
        print(f"‚ùå SemHash Turkish detector not available: {e}")
        print("\nTo install SemHash, run:")
        print("  pip install semhash")
        
        # Fallback to traditional duplicate detection
        print("\nüîÑ Falling back to traditional duplicate detection...")
        
        try:
            from src.data_quality.processors.duplicate_detector import TurkishDuplicateDetector
            
            config = {
                'text_column': 'text',
                'similarity_threshold': 0.8,
                'action': 'mark',
                'remove_stopwords': True,
                'normalize_text': True,
                'min_word_length': 2
            }
            
            detector = TurkishDuplicateDetector(config)
            result_df = detector.process(df)
            
            duplicate_count = result_df['is_duplicate'].sum() if 'is_duplicate' in result_df.columns else 0
            print(f"\nüìä Traditional detection results:")
            print(f"  Duplicates found: {duplicate_count}")
            print(f"  Unique texts: {len(result_df) - duplicate_count}")
            
        except ImportError as e2:
            print(f"‚ùå Traditional detector also not available: {e2}")
            print("\nNo duplicate detection methods available.")
    
    print("\n" + "="*50)
    print("Example completed!")

if __name__ == "__main__":
    main() 